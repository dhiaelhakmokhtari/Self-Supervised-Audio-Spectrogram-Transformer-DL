{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dHtXftddBXy"
   },
   "source": [
    "#### _Working SSAST Implementation_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### _libraries_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xhl6eQR9J_jr",
    "outputId": "2fe36f84-a77a-49bd-e6a9-e1abfc81683e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.11.8-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/texttable-1.7.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/igraph-0.11.8-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.13a0+0d33366-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      " Environment Ready.\n"
     ]
    }
   ],
   "source": [
    "# 2. Install Audio Libraries (Linux System + Python)\n",
    "!apt-get update -qq && apt-get install -y libsndfile1 ffmpeg > /dev/null\n",
    "!pip install timm==0.4.5 torchaudio soundfile pandas matplotlib > /dev/null\n",
    "\n",
    "print(\" Environment Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### _audio check_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9cgoDESKA6C",
    "outputId": "0d899453-349c-43c0-dc1d-8cf5d762b5ce"
   },
   "outputs": [],
   "source": [
    "# Cell 2: Transfer Data for Speed\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CONFIGURATION: EDIT THIS PATH ---\n",
    "# Where did you put your files in Drive?\n",
    "DRIVE_PROJECT_PATH = \"SSAST-Project\"\n",
    "# -------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPhJk-ZTO8kf",
    "outputId": "2b0c7b62-feb0-4fbb-97dc-27507eb54358",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell: Data Integrity Check\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "csv_path = \"metadata/train.csv\"\n",
    "def check_data_health(csv_path):\n",
    "    print(f\"ðŸ©º Checking health of dataset: {csv_path}\")\n",
    "\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {csv_path}\")\n",
    "        return\n",
    "\n",
    "    bad_files = []\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        file_path = row['filepath']\n",
    "\n",
    "        # 1. Check if file exists\n",
    "        if not os.path.exists(file_path):\n",
    "            bad_files.append((file_path, \"File Not Found\"))\n",
    "            continue\n",
    "\n",
    "        # 2. Check if file is empty\n",
    "        if os.path.getsize(file_path) < 100: # WAV header is ~44 bytes\n",
    "            bad_files.append((file_path, \"File Empty (<100 bytes)\"))\n",
    "            continue\n",
    "\n",
    "        # 3. Try to read audio\n",
    "        try:\n",
    "            sf.read(file_path)\n",
    "        except Exception as e:\n",
    "            # We catch the generic exception because soundfile might crash printing the specific one\n",
    "            bad_files.append((file_path, \"Corrupt Audio Header/Data\"))\n",
    "\n",
    "    if len(bad_files) == 0:\n",
    "        print(\"\\nDataset is HEALTHY! No corrupt files found.\")\n",
    "    else:\n",
    "        print(f\"\\n FOUND {len(bad_files)} BAD FILES!\")\n",
    "        print(\"Here are the first 5 culprits:\")\n",
    "        for path, reason in bad_files[:21]:\n",
    "            print(f\"  - {path} : {reason}\")\n",
    "\n",
    "        print(\"\\n RECOMMENDATION: Delete these files from your 'data' folder and remove them from your CSV.\")\n",
    "\n",
    "# Run check on Train and Val\n",
    "check_data_health(\"metadata/train.csv\")\n",
    "check_data_health(\"metadata/val.csv\")\n",
    "check_data_health(\"metadata/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qGNf3AK4T9ZS",
    "outputId": "28a067da-06d9-4f34-a54c-3d0c89365c30"
   },
   "outputs": [],
   "source": [
    "# Cell: Fix Corrupt CSV Entry\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"metadata/train.csv\"\n",
    "bad_file = \"./data/gtzan_10s/reggae/reggae.00088_0.wav\"\n",
    "\n",
    "# Load\n",
    "df = pd.read_csv(csv_path)\n",
    "initial_len = len(df)\n",
    "\n",
    "# Filter out the bad file\n",
    "df = df[df['filepath'] != bad_file]\n",
    "\n",
    "# Save back\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"   Fixed {csv_path}\")\n",
    "print(f\"   Removed: {bad_file}\")\n",
    "print(f\"   Rows: {initial_len} -> {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### _dataset loading_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "llbtNngB0wWu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Ready: 2390 Train, 295 Val.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Dataset (With SpecAugment added)\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GTZAN_Metadata_Dataset(Dataset):\n",
    "    # [CHANGE 1] Add 'augment' parameter (Default is False)\n",
    "    def __init__(self, csv_path, augment=False):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.augment = augment # Save the flag\n",
    "        self.target_sr = 16000\n",
    "        self.target_length = 1024 # frames\n",
    "\n",
    "        # Mapping from string labels to int\n",
    "        self.classes = sorted(self.df['label'].unique().tolist())\n",
    "        self.cls_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "        # SSAST Normalization Stats\n",
    "        self.norm_mean = -4.2677393\n",
    "        self.norm_std = 4.5689974\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # FIX PATH logic (Preserved from your code)\n",
    "        filename = os.path.basename(row['filepath'])\n",
    "        label_str = row['label']\n",
    "        genre_folder = label_str\n",
    "\n",
    "        # Construct the safe local path\n",
    "        audio_path = f\"./data/gtzan_10s/{genre_folder}/{filename}\"\n",
    "\n",
    "        label = self.cls_to_idx[label_str]\n",
    "\n",
    "        # 1. Load\n",
    "        audio_np, sr = sf.read(audio_path)\n",
    "        waveform = torch.from_numpy(audio_np).float()\n",
    "        if waveform.dim() == 1: waveform = waveform.unsqueeze(0)\n",
    "\n",
    "        # 2. Resample\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
    "\n",
    "        # 3. Spectrogram\n",
    "        fbank = torchaudio.compliance.kaldi.fbank(\n",
    "            waveform, htk_compat=True, sample_frequency=16000, use_energy=False,\n",
    "            window_type='hanning', num_mel_bins=128, dither=0.0, frame_shift=10\n",
    "        )\n",
    "\n",
    "        # [CHANGE 2] Apply SpecAugment ONLY if augment=True\n",
    "        if self.augment:\n",
    "            # Mask Frequency (Horizontal stripes) - Mask up to 48 bins\n",
    "            fbank = torchaudio.transforms.FrequencyMasking(freq_mask_param=48)(fbank.unsqueeze(0)).squeeze(0)\n",
    "            # Mask Time (Vertical stripes) - Mask up to 192 frames\n",
    "            fbank = torchaudio.transforms.TimeMasking(time_mask_param=192)(fbank.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        # 4. Pad/Crop\n",
    "        n_frames = fbank.shape[0]\n",
    "        p = self.target_length - n_frames\n",
    "        if p > 0:\n",
    "            m = torch.nn.ZeroPad2d((0, 0, 0, p))\n",
    "            fbank = m(fbank)\n",
    "        elif p < 0:\n",
    "            fbank = fbank[:self.target_length, :]\n",
    "\n",
    "        # 5. Normalize\n",
    "        fbank = (fbank - self.norm_mean) / (self.norm_std * 2)\n",
    "\n",
    "        return fbank, label\n",
    "\n",
    "# [CHANGE 3] Enable augmentation for Train, keep False for Val/Test\n",
    "train_ds = GTZAN_Metadata_Dataset(\"metadata/train.csv\", augment=True)\n",
    "val_ds   = GTZAN_Metadata_Dataset(\"metadata/val.csv\", augment=False)\n",
    "test_ds  = GTZAN_Metadata_Dataset(\"metadata/test.csv\", augment=False)\n",
    "\n",
    "# Create Loaders (Batch sizes kept as 32 as requested)\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=8)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "print(f\"Data Ready: {len(train_ds)} Train, {len(val_ds)} Val.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Dataset Updated with Softer Augmentation.\n",
      "Data Ready: 2390 Train, 295 Val.\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Dataset (Updated: Softer Augmentation)\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class GTZAN_Metadata_Dataset(Dataset):\n",
    "    def __init__(self, csv_path, augment=False):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.augment = augment \n",
    "        self.target_sr = 16000 \n",
    "        self.target_length = 1024 \n",
    "        \n",
    "        self.classes = [\n",
    "            'blues', 'classical', 'country', 'disco', 'hiphop', \n",
    "            'jazz', 'metal', 'pop', 'reggae', 'rock'\n",
    "        ]\n",
    "        self.cls_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        \n",
    "        self.norm_mean = -4.2677393\n",
    "        self.norm_std = 4.5689974\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        filename = os.path.basename(row['filepath']) \n",
    "        label_str = row['label']\n",
    "        genre_folder = label_str \n",
    "        \n",
    "        audio_path = f\"./data/gtzan_10s/{genre_folder}/{filename}\"\n",
    "        label = self.cls_to_idx[label_str]\n",
    "        \n",
    "        # 1. Load\n",
    "        if not os.path.exists(audio_path):\n",
    "            if os.path.exists(row['filepath']):\n",
    "                audio_path = row['filepath']\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"âŒ CANNOT FIND FILE: {audio_path}\")\n",
    "\n",
    "        audio_np, sr = sf.read(audio_path)\n",
    "        waveform = torch.from_numpy(audio_np).float()\n",
    "        if waveform.dim() == 1: waveform = waveform.unsqueeze(0)\n",
    "\n",
    "        # 2. Resample\n",
    "        if sr != 16000:\n",
    "            waveform = torchaudio.transforms.Resample(sr, 16000)(waveform)\n",
    "\n",
    "        # 3. Spectrogram\n",
    "        fbank = torchaudio.compliance.kaldi.fbank(\n",
    "            waveform, htk_compat=True, sample_frequency=16000, use_energy=False,\n",
    "            window_type='hanning', num_mel_bins=128, dither=0.0, frame_shift=10\n",
    "        )\n",
    "        \n",
    "        # 4. Augmentation (SOFTER VERSION)\n",
    "        # [CHANGED] 48->24, 192->96\n",
    "        if self.augment:\n",
    "             fbank = torchaudio.transforms.FrequencyMasking(freq_mask_param=36)(fbank.unsqueeze(0)).squeeze(0)\n",
    "             fbank = torchaudio.transforms.TimeMasking(time_mask_param=144)(fbank.unsqueeze(0)).squeeze(0)\n",
    "\n",
    "        # 5. Pad/Crop\n",
    "        n_frames = fbank.shape[0]\n",
    "        p = self.target_length - n_frames\n",
    "        if p > 0:\n",
    "            m = torch.nn.ZeroPad2d((0, 0, 0, p))\n",
    "            fbank = m(fbank)\n",
    "        elif p < 0:\n",
    "            fbank = fbank[:self.target_length, :]\n",
    "            \n",
    "        # 6. Normalize\n",
    "        fbank = (fbank - self.norm_mean) / (self.norm_std * 2)\n",
    "        \n",
    "        return fbank, label\n",
    "\n",
    "# Re-Initialize Loaders Immediately to apply changes\n",
    "train_ds = GTZAN_Metadata_Dataset(\"metadata/train.csv\", augment=True)\n",
    "val_ds   = GTZAN_Metadata_Dataset(\"metadata/val.csv\", augment=False)\n",
    "test_ds  = GTZAN_Metadata_Dataset(\"metadata/test.csv\", augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=8)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=8)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"âœ… Dataset Updated with Softer Augmentation.\")\n",
    "print(f\"Data Ready: {len(train_ds)} Train, {len(val_ds)} Val.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### _models_ fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### SSAST Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZSAKxYc3dKAL",
    "outputId": "e2c695cb-9638-42a3-f64b-5f15c09fa372",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 4: SSAST Training (Saves Every Epoch) same as 78.22% accuracy on test above this\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from ast_models import ASTModel\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Use \"expandable_segments\" to handle memory fragmentation\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "WEIGHTS_PATH = \"SSAST-Base-Patch-400.pth\"\n",
    "SAVE_DIR = \"augment_16_1_8/\" # Folder to keep them organized\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# Reduced batch size to fit in memory\n",
    "BATCH_SIZE = 16\n",
    "# Accumulate gradients to simulate batch size of 32 (8 * 4 = 32)\n",
    "ACCUM_STEPS = 2\n",
    "# ---------------------\n",
    "\n",
    "# 1. Clear Memory first\n",
    "if 'ssast_model' in globals(): del ssast_model\n",
    "if 'optimizer' in globals(): del optimizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 2. Setup Device & Loaders\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Re-create loaders with smaller batch size\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "# 3. Initialize Model\n",
    "print(f\"Initializing SSAST...\")\n",
    "ssast_model = ASTModel(\n",
    "    label_dim=527, input_fdim=128, input_tdim=1024,\n",
    "    model_size='base', pretrain_stage=False,\n",
    "    load_pretrained_mdl_path=WEIGHTS_PATH,\n",
    "    fshape=16, tshape=16, fstride=10, tstride=10\n",
    ")\n",
    "\n",
    "# 4. Modify Head\n",
    "if hasattr(ssast_model, 'mlp_head'):\n",
    "    input_dim = ssast_model.mlp_head[1].in_features\n",
    "    ssast_model.mlp_head[1] = nn.Linear(input_dim, 10)\n",
    "    print(\"Modified mlp_head.\")\n",
    "else:\n",
    "    print(\"Error finding head. Using fallback.\")\n",
    "    ssast_model.head = nn.Linear(768, 10)\n",
    "\n",
    "ssast_model = ssast_model.to(device)\n",
    "\n",
    "# 5. Training Loop\n",
    "optimizer = optim.Adam(ssast_model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "print(\"Starting Fine-Tuning (Saving Every Epoch)...\")\n",
    "\n",
    "for epoch in range(100):\n",
    "    ssast_model.train()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Mixed Precision\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = ssast_model(x, task='ft_avgtok')\n",
    "            loss = criterion(out, y)\n",
    "            loss = loss / ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % ACCUM_STEPS == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * ACCUM_STEPS\n",
    "        _, preds = out.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += preds.eq(y).sum().item()\n",
    "\n",
    "    # Validation\n",
    "    ssast_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = ssast_model(x, task='ft_avgtok')\n",
    "            _, preds = out.max(1)\n",
    "            val_total += y.size(0)\n",
    "            val_correct += preds.eq(y).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "\n",
    "    # --- NEW SAVING LOGIC ---\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss_sum/len(train_loader):.4f} | Train: {train_acc:.1f}% | Val: {val_acc:.1f}%\")\n",
    "\n",
    "    # Create unique filename: \"epoch1_T99.0_V83.5.pth\"\n",
    "    filename = f\"epoch{epoch+1}_T{train_acc:.1f}_V{val_acc:.1f}.pth\"\n",
    "    save_path = os.path.join(SAVE_DIR, filename)\n",
    "\n",
    "    torch.save(ssast_model.state_dict(), save_path)\n",
    "    print(f\" Saved: {filename}\")\n",
    "\n",
    "print(\"\\n Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### SSAST Training Optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gUbjn2Lqiq7B"
   },
   "outputs": [],
   "source": [
    "# Cell 4: SSAST Training (Saves Every Epoch with Custom Name) Optimised above but saves every epoch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from ast_models import ASTModel\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "WEIGHTS_PATH = \"SSAST-Base-Patch-400.pth\"\n",
    "# Base folder for saving checkpoints\n",
    "SAVE_DIR = \"checkpoints_optimized_150E_16_2/\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# STABLE SETTINGS\n",
    "BATCH_SIZE = 16\n",
    "ACCUM_STEPS = 2\n",
    "# ---------------------\n",
    "\n",
    "# 1. Clear Memory\n",
    "if 'ssast_model' in globals(): del ssast_model\n",
    "if 'optimizer' in globals(): del optimizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 2. Setup Device & Loaders\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Re-create loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "# 3. Initialize Model\n",
    "print(f\"Initializing SSAST...\")\n",
    "ssast_model = ASTModel(\n",
    "    label_dim=527, input_fdim=128, input_tdim=1024,\n",
    "    model_size='base', pretrain_stage=False,\n",
    "    load_pretrained_mdl_path=WEIGHTS_PATH,\n",
    "    fshape=16, tshape=16, fstride=10, tstride=10\n",
    ")\n",
    "\n",
    "# 4. Modify Head\n",
    "if hasattr(ssast_model, 'mlp_head'):\n",
    "    input_dim = ssast_model.mlp_head[1].in_features\n",
    "    ssast_model.mlp_head[1] = nn.Linear(input_dim, 10)\n",
    "    print(\" Modified mlp_head.\")\n",
    "else:\n",
    "    print(\" Error finding head. Using fallback.\")\n",
    "    ssast_model.head = nn.Linear(768, 10)\n",
    "\n",
    "ssast_model = ssast_model.to(device)\n",
    "\n",
    "# 5. Tuned Optimizer & Scheduler\n",
    "optimizer = optim.AdamW(ssast_model.parameters(), lr=1e-5, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=150)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# Track best just for display\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(\" Starting Fine-Tuning (Saving EVERY Epoch)...\")\n",
    "\n",
    "for epoch in range(150):\n",
    "    ssast_model.train()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        # Mixed Precision\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = ssast_model(x, task='ft_avgtok')\n",
    "            loss = criterion(out, y)\n",
    "            loss = loss / ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % ACCUM_STEPS == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * ACCUM_STEPS\n",
    "        _, preds = out.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += preds.eq(y).sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Validation\n",
    "    ssast_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = ssast_model(x, task='ft_avgtok')\n",
    "            _, preds = out.max(1)\n",
    "            val_total += y.size(0)\n",
    "            val_correct += preds.eq(y).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "\n",
    "    # Update Best Record (for display)\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        is_best_str = \" (New Best)\"\n",
    "    else:\n",
    "        is_best_str = \"\"\n",
    "\n",
    "    # --- SAVE EVERY EPOCH ---\n",
    "    # Construct filename: ssast_model_epoch1_accT99.5accval83.2_optimized.pth\n",
    "    filename = f\"ssast_model_epoch{epoch+1}_accT{train_acc:.1f}accval{val_acc:.1f}_optimized.pth\"\n",
    "    full_save_path = os.path.join(SAVE_DIR, filename)\n",
    "\n",
    "    torch.save(ssast_model.state_dict(), full_save_path)\n",
    "\n",
    "    # Print status\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss_sum/len(train_loader):.4f} | LR: {current_lr:.2e} | Train: {train_acc:.1f}% | Val: {val_acc:.1f}% {is_best_str}\")\n",
    "    print(f\"    ðŸ’¾ Saved: {filename}\")\n",
    "\n",
    "print(\"\\n Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### SSAST Training Optimized + LLRD + Label Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Initializing SSAST...\n",
      "now load a SSL pretrained models from SSAST-Base-Patch-400.pth\n",
      "pretraining patch split stride: frequency=16, time=16\n",
      "pretraining patch shape: frequency=16, time=16\n",
      "pretraining patch array dimension: frequency=8, time=64\n",
      "pretraining number of patches=512\n",
      "fine-tuning patch split stride: frequncey=10, time=10\n",
      "fine-tuning number of patches=1212\n",
      "Starting Training (170 Epochs) with LLRD...\n",
      "-> Backbone LR: 5e-6 (Slow)\n",
      "-> Head LR:     1e-4 (Fast)\n",
      "Epoch 1 | Loss: 2.2431 | LR(Body): 5.00e-06 | Train: 17.9% | Val: 31.5%  (New Best)\n",
      "    Saved: ssast_epoch1_T17.9_V31.5.pth\n",
      "Epoch 2 | Loss: 1.9442 | LR(Body): 5.00e-06 | Train: 33.4% | Val: 46.8%  (New Best)\n",
      "    Saved: ssast_epoch2_T33.4_V46.8.pth\n",
      "Epoch 3 | Loss: 1.7612 | LR(Body): 5.00e-06 | Train: 43.8% | Val: 57.3%  (New Best)\n",
      "    Saved: ssast_epoch3_T43.8_V57.3.pth\n",
      "Epoch 4 | Loss: 1.6562 | LR(Body): 4.99e-06 | Train: 46.9% | Val: 61.0%  (New Best)\n",
      "    Saved: ssast_epoch4_T46.9_V61.0.pth\n",
      "Epoch 5 | Loss: 1.5600 | LR(Body): 4.99e-06 | Train: 53.1% | Val: 65.4%  (New Best)\n",
      "    Saved: ssast_epoch5_T53.1_V65.4.pth\n",
      "Epoch 6 | Loss: 1.4661 | LR(Body): 4.98e-06 | Train: 57.5% | Val: 67.8%  (New Best)\n",
      "    Saved: ssast_epoch6_T57.5_V67.8.pth\n",
      "Epoch 7 | Loss: 1.4316 | LR(Body): 4.98e-06 | Train: 58.7% | Val: 67.8% \n",
      "    Saved: ssast_epoch7_T58.7_V67.8.pth\n",
      "Epoch 8 | Loss: 1.3741 | LR(Body): 4.97e-06 | Train: 62.0% | Val: 68.5%  (New Best)\n",
      "    Saved: ssast_epoch8_T62.0_V68.5.pth\n",
      "Epoch 9 | Loss: 1.3294 | LR(Body): 4.97e-06 | Train: 63.4% | Val: 68.8%  (New Best)\n",
      "    Saved: ssast_epoch9_T63.4_V68.8.pth\n",
      "Epoch 10 | Loss: 1.2864 | LR(Body): 4.96e-06 | Train: 65.5% | Val: 74.9%  (New Best)\n",
      "    Saved: ssast_epoch10_T65.5_V74.9.pth\n",
      "Epoch 11 | Loss: 1.2316 | LR(Body): 4.95e-06 | Train: 68.2% | Val: 75.9%  (New Best)\n",
      "    Saved: ssast_epoch11_T68.2_V75.9.pth\n",
      "Epoch 12 | Loss: 1.2268 | LR(Body): 4.94e-06 | Train: 67.9% | Val: 74.6% \n",
      "    Saved: ssast_epoch12_T67.9_V74.6.pth\n",
      "Epoch 13 | Loss: 1.1983 | LR(Body): 4.93e-06 | Train: 70.8% | Val: 74.6% \n",
      "    Saved: ssast_epoch13_T70.8_V74.6.pth\n",
      "Epoch 14 | Loss: 1.1768 | LR(Body): 4.92e-06 | Train: 69.7% | Val: 70.2% \n",
      "    Saved: ssast_epoch14_T69.7_V70.2.pth\n",
      "Epoch 15 | Loss: 1.1432 | LR(Body): 4.90e-06 | Train: 71.5% | Val: 75.3% \n",
      "    Saved: ssast_epoch15_T71.5_V75.3.pth\n",
      "Epoch 16 | Loss: 1.1322 | LR(Body): 4.89e-06 | Train: 72.6% | Val: 76.6%  (New Best)\n",
      "    Saved: ssast_epoch16_T72.6_V76.6.pth\n",
      "Epoch 17 | Loss: 1.0972 | LR(Body): 4.88e-06 | Train: 74.6% | Val: 76.6% \n",
      "    Saved: ssast_epoch17_T74.6_V76.6.pth\n",
      "Epoch 18 | Loss: 1.0775 | LR(Body): 4.86e-06 | Train: 75.2% | Val: 76.6% \n",
      "    Saved: ssast_epoch18_T75.2_V76.6.pth\n",
      "Epoch 19 | Loss: 1.0617 | LR(Body): 4.85e-06 | Train: 75.9% | Val: 75.9% \n",
      "    Saved: ssast_epoch19_T75.9_V75.9.pth\n",
      "Epoch 20 | Loss: 1.0618 | LR(Body): 4.83e-06 | Train: 75.1% | Val: 79.3%  (New Best)\n",
      "    Saved: ssast_epoch20_T75.1_V79.3.pth\n",
      "Epoch 21 | Loss: 1.0276 | LR(Body): 4.81e-06 | Train: 76.8% | Val: 77.3% \n",
      "    Saved: ssast_epoch21_T76.8_V77.3.pth\n",
      "Epoch 22 | Loss: 1.0285 | LR(Body): 4.80e-06 | Train: 76.2% | Val: 76.3% \n",
      "    Saved: ssast_epoch22_T76.2_V76.3.pth\n",
      "Epoch 23 | Loss: 1.0048 | LR(Body): 4.78e-06 | Train: 77.3% | Val: 78.0% \n",
      "    Saved: ssast_epoch23_T77.3_V78.0.pth\n",
      "Epoch 24 | Loss: 1.0257 | LR(Body): 4.76e-06 | Train: 77.0% | Val: 75.6% \n",
      "    Saved: ssast_epoch24_T77.0_V75.6.pth\n",
      "Epoch 25 | Loss: 0.9781 | LR(Body): 4.74e-06 | Train: 79.1% | Val: 78.3% \n",
      "    Saved: ssast_epoch25_T79.1_V78.3.pth\n",
      "Epoch 26 | Loss: 0.9825 | LR(Body): 4.72e-06 | Train: 79.2% | Val: 78.3% \n",
      "    Saved: ssast_epoch26_T79.2_V78.3.pth\n",
      "Epoch 27 | Loss: 0.9885 | LR(Body): 4.70e-06 | Train: 78.3% | Val: 77.3% \n",
      "    Saved: ssast_epoch27_T78.3_V77.3.pth\n",
      "Epoch 28 | Loss: 0.9897 | LR(Body): 4.67e-06 | Train: 78.1% | Val: 78.6% \n",
      "    Saved: ssast_epoch28_T78.1_V78.6.pth\n",
      "Epoch 29 | Loss: 0.9659 | LR(Body): 4.65e-06 | Train: 79.3% | Val: 80.0%  (New Best)\n",
      "    Saved: ssast_epoch29_T79.3_V80.0.pth\n",
      "Epoch 30 | Loss: 0.9628 | LR(Body): 4.63e-06 | Train: 80.2% | Val: 79.7% \n",
      "    Saved: ssast_epoch30_T80.2_V79.7.pth\n",
      "Epoch 31 | Loss: 0.9581 | LR(Body): 4.60e-06 | Train: 80.1% | Val: 81.7%  (New Best)\n",
      "    Saved: ssast_epoch31_T80.1_V81.7.pth\n",
      "Epoch 32 | Loss: 0.9303 | LR(Body): 4.58e-06 | Train: 81.7% | Val: 81.7% \n",
      "    Saved: ssast_epoch32_T81.7_V81.7.pth\n",
      "Epoch 33 | Loss: 0.9231 | LR(Body): 4.55e-06 | Train: 81.5% | Val: 80.0% \n",
      "    Saved: ssast_epoch33_T81.5_V80.0.pth\n",
      "Epoch 34 | Loss: 0.9408 | LR(Body): 4.52e-06 | Train: 81.1% | Val: 80.3% \n",
      "    Saved: ssast_epoch34_T81.1_V80.3.pth\n",
      "Epoch 35 | Loss: 0.9259 | LR(Body): 4.50e-06 | Train: 81.2% | Val: 75.3% \n",
      "    Saved: ssast_epoch35_T81.2_V75.3.pth\n",
      "Epoch 36 | Loss: 0.9351 | LR(Body): 4.47e-06 | Train: 80.5% | Val: 79.3% \n",
      "    Saved: ssast_epoch36_T80.5_V79.3.pth\n",
      "Epoch 37 | Loss: 0.9026 | LR(Body): 4.44e-06 | Train: 82.2% | Val: 79.7% \n",
      "    Saved: ssast_epoch37_T82.2_V79.7.pth\n",
      "Epoch 38 | Loss: 0.9234 | LR(Body): 4.41e-06 | Train: 81.4% | Val: 81.0% \n",
      "    Saved: ssast_epoch38_T81.4_V81.0.pth\n",
      "Epoch 39 | Loss: 0.9016 | LR(Body): 4.38e-06 | Train: 82.9% | Val: 80.0% \n",
      "    Saved: ssast_epoch39_T82.9_V80.0.pth\n",
      "Epoch 40 | Loss: 0.9209 | LR(Body): 4.35e-06 | Train: 81.9% | Val: 81.0% \n",
      "    Saved: ssast_epoch40_T81.9_V81.0.pth\n",
      "Epoch 41 | Loss: 0.9165 | LR(Body): 4.32e-06 | Train: 81.9% | Val: 80.7% \n",
      "    Saved: ssast_epoch41_T81.9_V80.7.pth\n",
      "Epoch 42 | Loss: 0.9041 | LR(Body): 4.28e-06 | Train: 82.0% | Val: 79.7% \n",
      "    Saved: ssast_epoch42_T82.0_V79.7.pth\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: SSAST Training (Scenario B: LLRD + 150 Epochs)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from ast_models import ASTModel\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "WEIGHTS_PATH = \"SSAST-Base-Patch-400.pth\"\n",
    "\n",
    "# [CHANGED] New folder so we don't overwrite your 80% model\n",
    "SAVE_DIR = \"checkpoints_LLRD_150E/\" \n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# SETTINGS\n",
    "BATCH_SIZE = 16\n",
    "ACCUM_STEPS = 2\n",
    "# [CHANGED] Increased epochs to give the slow learning rate time to work\n",
    "NUM_EPOCHS = 170  \n",
    "# ---------------------\n",
    "\n",
    "# 1. Clear Memory\n",
    "if 'ssast_model' in globals(): del ssast_model\n",
    "if 'optimizer' in globals(): del optimizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 2. Setup Device & Loaders\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "# 3. Initialize Model\n",
    "print(f\"Initializing SSAST...\")\n",
    "ssast_model = ASTModel(\n",
    "    label_dim=527, input_fdim=128, input_tdim=1024,\n",
    "    model_size='base', pretrain_stage=False,\n",
    "    load_pretrained_mdl_path=WEIGHTS_PATH,\n",
    "    fshape=16, tshape=16, fstride=10, tstride=10\n",
    ")\n",
    "\n",
    "# 4. Modify Head\n",
    "if hasattr(ssast_model, 'mlp_head'):\n",
    "    input_dim = ssast_model.mlp_head[1].in_features\n",
    "    ssast_model.mlp_head[1] = nn.Linear(input_dim, 10)\n",
    "else:\n",
    "    ssast_model.head = nn.Linear(768, 10)\n",
    "\n",
    "ssast_model = ssast_model.to(device)\n",
    "\n",
    "# ==============================================================================\n",
    "# [NEW] LAYER-WISE LEARNING RATE DECAY (LLRD) SETUP\n",
    "# ==============================================================================\n",
    "# Logic: We separate the model into two parts:\n",
    "# 1. The \"Head\" (New Classifier) -> Needs High LR (1e-4) to learn fast\n",
    "# 2. The \"Backbone\" (Pretrained AudioSet) -> Needs Low LR (5e-6) to not forget\n",
    "\n",
    "head_params = []\n",
    "backbone_params = []\n",
    "# These are the standard names for the classification layer in AST\n",
    "head_names = ['mlp_head', 'head'] \n",
    "\n",
    "for name, param in ssast_model.named_parameters():\n",
    "    if any(h in name for h in head_names):\n",
    "        head_params.append(param)\n",
    "    else:\n",
    "        backbone_params.append(param)\n",
    "\n",
    "# [CHANGED] Optimizer now takes a LIST of groups instead of model.parameters()\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': backbone_params, 'lr': 5e-6}, # Very slow learning for the body\n",
    "    {'params': head_params,     'lr': 1e-4}  # Fast learning for the head\n",
    "], weight_decay=0.01)\n",
    "\n",
    "# [CHANGED] Scheduler must match the new NUM_EPOCHS\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "\n",
    "# [NEW] Label Smoothing: Prevents the model from being \"too confident\"\n",
    "# This helps it generalize better when training for longer.\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "# ==============================================================================\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# Track best\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(f\"Starting Training ({NUM_EPOCHS} Epochs) with LLRD...\")\n",
    "print(f\"-> Backbone LR: 5e-6 (Slow)\")\n",
    "print(f\"-> Head LR:     1e-4 (Fast)\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    ssast_model.train()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            out = ssast_model(x, task='ft_avgtok')\n",
    "            loss = criterion(out, y)\n",
    "            loss = loss / ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % ACCUM_STEPS == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * ACCUM_STEPS\n",
    "        _, preds = out.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += preds.eq(y).sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    # [NEW] Get current LR specifically for the Body (group 0) to print\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Validation\n",
    "    ssast_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = ssast_model(x, task='ft_avgtok')\n",
    "            _, preds = out.max(1)\n",
    "            val_total += y.size(0)\n",
    "            val_correct += preds.eq(y).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        is_best_str = \" (New Best)\"\n",
    "    else:\n",
    "        is_best_str = \"\"\n",
    "\n",
    "    # Save\n",
    "    filename = f\"ssast_epoch{epoch+1}_T{train_acc:.1f}_V{val_acc:.1f}.pth\"\n",
    "    full_save_path = os.path.join(SAVE_DIR, filename)\n",
    "    torch.save(ssast_model.state_dict(), full_save_path)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss_sum/len(train_loader):.4f} | LR(Body): {current_lr:.2e} | Train: {train_acc:.1f}% | Val: {val_acc:.1f}% {is_best_str}\")\n",
    "    print(f\"    Saved: {filename}\")\n",
    "\n",
    "print(\"\\n Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "###### SSAST Training Optimized + LLRD + Label Smoothing + Parallelisme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: SSAST Training (Scenario B: LLRD + Parallelism + 150 Epochs)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from ast_models import ASTModel\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "WEIGHTS_PATH = \"SSAST-Base-Patch-400.pth\"\n",
    "\n",
    "# [CHANGED] New folder so we don't overwrite your 80% model\n",
    "SAVE_DIR = \"checkpoints_LLRD_150E/\" \n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "# SETTINGS\n",
    "# [NOTE] If using multiple GPUs, this BATCH_SIZE is the TOTAL across all GPUs.\n",
    "# E.g., if BATCH_SIZE=16 and you have 2 GPUs, each GPU gets 8 samples.\n",
    "BATCH_SIZE = 16 \n",
    "ACCUM_STEPS = 2\n",
    "NUM_EPOCHS = 170  \n",
    "# ---------------------\n",
    "\n",
    "# 1. Clear Memory\n",
    "if 'ssast_model' in globals(): del ssast_model\n",
    "if 'optimizer' in globals(): del optimizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# 2. Setup Device & Loaders\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Loaders\n",
    "# [NOTE] Num_workers is critical for keeping multi-GPUs fed. 8 is good.\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n",
    "\n",
    "# 3. Initialize Model\n",
    "print(f\"Initializing SSAST...\")\n",
    "ssast_model = ASTModel(\n",
    "    label_dim=527, input_fdim=128, input_tdim=1024,\n",
    "    model_size='base', pretrain_stage=False,\n",
    "    load_pretrained_mdl_path=WEIGHTS_PATH,\n",
    "    fshape=16, tshape=16, fstride=10, tstride=10\n",
    ")\n",
    "\n",
    "# 4. Modify Head\n",
    "if hasattr(ssast_model, 'mlp_head'):\n",
    "    input_dim = ssast_model.mlp_head[1].in_features\n",
    "    ssast_model.mlp_head[1] = nn.Linear(input_dim, 10)\n",
    "else:\n",
    "    ssast_model.head = nn.Linear(768, 10)\n",
    "\n",
    "ssast_model = ssast_model.to(device)\n",
    "\n",
    "# ==============================================================================\n",
    "# [NEW] LAYER-WISE LEARNING RATE DECAY (LLRD) SETUP\n",
    "# ==============================================================================\n",
    "head_params = []\n",
    "backbone_params = []\n",
    "head_names = ['mlp_head', 'head'] \n",
    "\n",
    "# We do this separation BEFORE wrapping in DataParallel to keep names simple\n",
    "for name, param in ssast_model.named_parameters():\n",
    "    if any(h in name for h in head_names):\n",
    "        head_params.append(param)\n",
    "    else:\n",
    "        backbone_params.append(param)\n",
    "\n",
    "optimizer = optim.AdamW([\n",
    "    {'params': backbone_params, 'lr': 5e-6}, # Slow Body\n",
    "    {'params': head_params,     'lr': 1e-4}  # Fast Head\n",
    "], weight_decay=0.01)\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.2) # High smoothing for \"Medium\" Augment\n",
    "\n",
    "# ==============================================================================\n",
    "# [NEW] PARALLELISM BLOCK\n",
    "# ==============================================================================\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"ðŸš€ Parallelism Enabled: Using {torch.cuda.device_count()} GPUs!\")\n",
    "    # Wraps the model to split the batch across GPUs automatically\n",
    "    ssast_model = nn.DataParallel(ssast_model)\n",
    "else:\n",
    "    print(\"â„¹ï¸ Parallelism Skipped: Single GPU detected.\")\n",
    "# ==============================================================================\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# Track best\n",
    "best_val_acc = 0.0\n",
    "\n",
    "print(f\"Starting Training ({NUM_EPOCHS} Epochs) with LLRD...\")\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    ssast_model.train()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.amp.autocast('cuda'):\n",
    "            # DataParallel automatically splits 'x' and runs forward on all GPUs\n",
    "            out = ssast_model(x, task='ft_avgtok')\n",
    "            loss = criterion(out, y)\n",
    "            loss = loss / ACCUM_STEPS\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (i + 1) % ACCUM_STEPS == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        loss_sum += loss.item() * ACCUM_STEPS\n",
    "        _, preds = out.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += preds.eq(y).sum().item()\n",
    "\n",
    "    scheduler.step()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    # Validation\n",
    "    ssast_model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = ssast_model(x, task='ft_avgtok')\n",
    "            _, preds = out.max(1)\n",
    "            val_total += y.size(0)\n",
    "            val_correct += preds.eq(y).sum().item()\n",
    "\n",
    "    train_acc = 100 * correct / total\n",
    "    val_acc = 100 * val_correct / val_total\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        is_best_str = \" (New Best)\"\n",
    "    else:\n",
    "        is_best_str = \"\"\n",
    "\n",
    "    # [CHANGED] Save Logic for Parallel Models\n",
    "    # If we used DataParallel, the real model is inside .module\n",
    "    # We unwrap it so you can load it easily later on a CPU or single GPU\n",
    "    if hasattr(ssast_model, 'module'):\n",
    "        state_dict = ssast_model.module.state_dict()\n",
    "    else:\n",
    "        state_dict = ssast_model.state_dict()\n",
    "\n",
    "    filename = f\"ssast_epoch{epoch+1}_T{train_acc:.1f}_V{val_acc:.1f}.pth\"\n",
    "    full_save_path = os.path.join(SAVE_DIR, filename)\n",
    "    \n",
    "    # Save the clean state_dict\n",
    "    torch.save(state_dict, full_save_path)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss_sum/len(train_loader):.4f} | LR(Body): {current_lr:.2e} | Train: {train_acc:.1f}% | Val: {val_acc:.1f}% {is_best_str}\")\n",
    "    print(f\"    Saved: {filename}\")\n",
    "\n",
    "print(\"\\n Training Complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### _testing and voting_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tyP6lH-LcJUJ",
    "outputId": "ee045007-f041-4d05-b6d6-6f0764dcaf61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Re-building model architecture...\n",
      "now load a SSL pretrained models from SSAST-Base-Patch-400.pth\n",
      "pretraining patch split stride: frequency=16, time=16\n",
      "pretraining patch shape: frequency=16, time=16\n",
      "pretraining patch array dimension: frequency=8, time=64\n",
      "pretraining number of patches=512\n",
      "fine-tuning patch split stride: frequncey=10, time=10\n",
      "fine-tuning number of patches=1212\n",
      "Loading weights from: checkpoints_LLRD_150E/ssast_epoch20_T94.2_V84.1.pth\n",
      "Evaluation on 303 Test Samples...\n",
      "------------------------------\n",
      "FINAL TEST ACCURACY: 76.57%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Final Test Evaluation (CPU/GPU Compatible)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from ast_models import ASTModel\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "BASE_WEIGHTS_PATH = \"SSAST-Base-Patch-400.pth\"\n",
    "# Ensure this matches the file you actually want to test!\n",
    "BEST_MODEL_PATH = \"checkpoints_LLRD_150E/ssast_epoch20_T94.2_V84.1.pth\"\n",
    "BATCH_SIZE = 16\n",
    "# ---------------------\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# 1. Load Test Data\n",
    "# (Using default dataset class)\n",
    "test_ds = GTZAN_Metadata_Dataset(\"metadata/test.csv\")\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "# 2. Re-Initialize Model Architecture\n",
    "print(f\"Re-building model architecture...\")\n",
    "ssast_model = ASTModel(\n",
    "    label_dim=527, input_fdim=128, input_tdim=1024,\n",
    "    model_size='base', pretrain_stage=False,\n",
    "    load_pretrained_mdl_path=BASE_WEIGHTS_PATH,\n",
    "    fshape=16, tshape=16, fstride=10, tstride=10\n",
    ")\n",
    "\n",
    "# 3. Modify Head\n",
    "if hasattr(ssast_model, 'mlp_head'):\n",
    "    input_dim = ssast_model.mlp_head[1].in_features\n",
    "    ssast_model.mlp_head[1] = nn.Linear(input_dim, 10)\n",
    "else:\n",
    "    ssast_model.head = nn.Linear(768, 10)\n",
    "\n",
    "ssast_model = ssast_model.to(device)\n",
    "\n",
    "# 4. Load Best Weights (Fixed for CPU)\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(f\"Loading weights from: {BEST_MODEL_PATH}\")\n",
    "    # [FIX]: Added map_location=device to handle CPU loading\n",
    "    ssast_model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "else:\n",
    "    print(f\"Warning: {BEST_MODEL_PATH} not found. Using initialized weights.\")\n",
    "\n",
    "# 5. Run Evaluation\n",
    "print(f\"Evaluation on {len(test_ds)} Test Samples...\")\n",
    "\n",
    "ssast_model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # Use Mixed Precision (only works on CUDA, so we disable it for CPU safety)\n",
    "        if device.type == 'cuda':\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = ssast_model(x, task='ft_avgtok')\n",
    "        else:\n",
    "            # CPU Fallback\n",
    "            out = ssast_model(x, task='ft_avgtok')\n",
    "\n",
    "        _, preds = out.max(1)\n",
    "        total += y.size(0)\n",
    "        correct += preds.eq(y).sum().item()\n",
    "\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "final_acc = 100 * correct / total\n",
    "print(\"-\" * 30)\n",
    "print(f\"FINAL TEST ACCURACY: {final_acc:.2f}%\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—³ï¸ Starting Hard Voting (Counting Votes)...\n",
      "âœ… Processed 303 clips.\n",
      "------------------------------\n",
      "ðŸŽµ FINAL SONG ACCURACY (Hard Voting): 79.21%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Cell 8 (Update): Hard Voting (Robust Democracy)\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from collections import Counter\n",
    "\n",
    "print(f\"ðŸ—³ï¸ Starting Hard Voting (Counting Votes)...\")\n",
    "\n",
    "ssast_model.eval()\n",
    "song_votes = {}\n",
    "song_probs = {}  # Keep probs for tie-breaking\n",
    "song_truth = {}\n",
    "processed_clips = 0\n",
    "\n",
    "BATCH_SIZE = test_loader.batch_size\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # Get probabilities\n",
    "        if device.type == 'cuda':\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                logits = ssast_model(x, task='ft_avgtok')\n",
    "                probs = torch.softmax(logits, dim=1)\n",
    "        else:\n",
    "            logits = ssast_model(x, task='ft_avgtok')\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "        \n",
    "        probs = probs.cpu().numpy()\n",
    "        preds = probs.argmax(axis=1) # Hard predictions\n",
    "        labels = y.numpy()\n",
    "        \n",
    "        # Batch offset\n",
    "        start_idx = i * BATCH_SIZE \n",
    "        \n",
    "        for j in range(len(labels)):\n",
    "            global_idx = start_idx + j\n",
    "            \n",
    "            row = test_ds.df.iloc[global_idx]\n",
    "            filename = os.path.basename(row['filepath'])\n",
    "            \n",
    "            # Extract Song ID (\"blues.00001\")\n",
    "            song_id = filename.rsplit('_', 1)[0] \n",
    "            \n",
    "            if song_id not in song_votes:\n",
    "                song_votes[song_id] = []\n",
    "                song_probs[song_id] = []\n",
    "                song_truth[song_id] = labels[j]\n",
    "            \n",
    "            song_votes[song_id].append(preds[j])\n",
    "            song_probs[song_id].append(probs[j])\n",
    "            processed_clips += 1\n",
    "\n",
    "print(f\"âœ… Processed {processed_clips} clips.\")\n",
    "\n",
    "# Calculate Accuracy with Hard Voting\n",
    "correct_songs = 0\n",
    "total_songs = 0\n",
    "\n",
    "for song_id, votes in song_votes.items():\n",
    "    # 1. Count the votes (e.g., {0: 2, 1: 1})\n",
    "    counts = Counter(votes)\n",
    "    \n",
    "    # 2. Find the winner\n",
    "    # most_common(1) returns [(Label, Count)]\n",
    "    winner, vote_count = counts.most_common(1)[0]\n",
    "    \n",
    "    # 3. Handle Ties (1-1-1 split)\n",
    "    # If the winner has only 1 vote (and there are 3 clips), it's a 3-way tie.\n",
    "    if vote_count == 1 and len(votes) == 3:\n",
    "        # Fallback to Soft Voting (Average probabilities)\n",
    "        avg_score = np.mean(song_probs[song_id], axis=0)\n",
    "        winner = np.argmax(avg_score)\n",
    "    \n",
    "    true_label = song_truth[song_id]\n",
    "    \n",
    "    if winner == true_label:\n",
    "        correct_songs += 1\n",
    "    total_songs += 1\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(f\"ðŸŽµ FINAL SONG ACCURACY (Hard Voting): {100 * correct_songs / total_songs:.2f}%\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### _confusion matrix_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Final Confusion Matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. Get all predictions\n",
    "print(\"ðŸ“Š Generating Confusion Matrix...\")\n",
    "ssast_model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # Inference\n",
    "        if device.type == 'cuda':\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                logits = ssast_model(x, task='ft_avgtok')\n",
    "        else:\n",
    "            logits = ssast_model(x, task='ft_avgtok')\n",
    "            \n",
    "        _, preds = logits.max(1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(y.numpy())\n",
    "\n",
    "# 2. Compute Matrix\n",
    "# Get class names in correct order (0 to 9)\n",
    "classes = test_ds.classes \n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "# 3. Plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.ylabel('Actual Genre')\n",
    "plt.xlabel('Predicted Genre')\n",
    "plt.title(f'SSAST Confusion Matrix (Clip Level) - Accuracy: {100*np.mean(np.array(all_preds)==np.array(all_labels)):.1f}%')\n",
    "plt.show()\n",
    "\n",
    "# Save it\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "print(\"âœ… Saved confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Final Song-Level Confusion Matrix (The \"Clean\" One)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "\n",
    "print(\"ðŸ“Š Generating Song-Level Confusion Matrix...\")\n",
    "\n",
    "ssast_model.eval()\n",
    "song_votes = {}\n",
    "song_truth = {}\n",
    "BATCH_SIZE = test_loader.batch_size\n",
    "\n",
    "# 1. Collect all votes\n",
    "with torch.no_grad():\n",
    "    for i, (x, y) in enumerate(test_loader):\n",
    "        x = x.to(device)\n",
    "        \n",
    "        # Get predictions\n",
    "        if device.type == 'cuda':\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                logits = ssast_model(x, task='ft_avgtok')\n",
    "        else:\n",
    "            logits = ssast_model(x, task='ft_avgtok')\n",
    "            \n",
    "        _, preds = logits.max(1)\n",
    "        preds = preds.cpu().numpy()\n",
    "        labels = y.numpy()\n",
    "        \n",
    "        start_idx = i * BATCH_SIZE \n",
    "        for j in range(len(labels)):\n",
    "            global_idx = start_idx + j\n",
    "            row = test_ds.df.iloc[global_idx]\n",
    "            filename = os.path.basename(row['filepath'])\n",
    "            song_id = filename.rsplit('_', 1)[0]\n",
    "            \n",
    "            if song_id not in song_votes:\n",
    "                song_votes[song_id] = []\n",
    "                song_truth[song_id] = labels[j]\n",
    "            \n",
    "            song_votes[song_id].append(preds[j])\n",
    "\n",
    "# 2. Apply Voting to get Final Labels\n",
    "final_preds = []\n",
    "final_truth = []\n",
    "\n",
    "for song_id, votes in song_votes.items():\n",
    "    # Hard Voting\n",
    "    c = Counter(votes)\n",
    "    winner, count = c.most_common(1)[0]\n",
    "    \n",
    "    final_preds.append(winner)\n",
    "    final_truth.append(song_truth[song_id])\n",
    "\n",
    "# 3. Plot\n",
    "classes = test_ds.classes \n",
    "cm = confusion_matrix(final_truth, final_preds)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens', \n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.ylabel('Actual Genre')\n",
    "plt.xlabel('Predicted Genre (After Voting)')\n",
    "plt.title(f'SSAST Final Confusion Matrix (Song Level) - Accuracy: {100*np.mean(np.array(final_preds)==np.array(final_truth)):.1f}%')\n",
    "plt.savefig(\"confusion_matrix_song_level.png\")\n",
    "plt.show()\n",
    "print(\"âœ… Saved confusion_matrix_song_level.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ Scanning relative to: /home/laughing_gates/workdir/SSAST-Project\n",
      "   Current Folder Size: 4.2G\n",
      "\n",
      "ðŸ“‚ Scanning Parent: /home/laughing_gates/workdir\n",
      "   > Measuring streamlit...\n",
      "   > Measuring SSAST-Project...\n",
      "   > Measuring .ipynb_checkpoints...\n",
      "\n",
      "ðŸš¨ BIGGEST FOLDERS IN PARENT:\n",
      "   4.2G       SSAST-Project\n",
      "   625.0B     streamlit\n",
      "   0.0B       .ipynb_checkpoints\n",
      "\n",
      "ðŸ—‘ï¸ Trash Size: 33.5G\n",
      "   (Run 'import shutil; shutil.rmtree(\"/home/laughing_gates/.local/share/Trash\")' to empty it)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def get_dir_size(path):\n",
    "    total = 0\n",
    "    try:\n",
    "        for entry in os.scandir(path):\n",
    "            if entry.is_file():\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir(follow_symlinks=False):\n",
    "                total += get_dir_size(entry.path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return total\n",
    "\n",
    "def fmt(b):\n",
    "    for u in ['B', 'K', 'M', 'G']:\n",
    "        if b < 1024: return f\"{b:.1f}{u}\"\n",
    "        b /= 1024\n",
    "    return f\"{b:.1f}T\"\n",
    "\n",
    "current = os.getcwd()\n",
    "print(f\"ðŸ“ Scanning relative to: {current}\")\n",
    "\n",
    "# 1. Check Current Folder\n",
    "print(f\"   Current Folder Size: {fmt(get_dir_size(current))}\")\n",
    "\n",
    "# 2. Check Parent Folder\n",
    "parent = os.path.dirname(current)\n",
    "print(f\"\\nðŸ“‚ Scanning Parent: {parent}\")\n",
    "try:\n",
    "    subdirs = []\n",
    "    for entry in os.scandir(parent):\n",
    "        if entry.is_dir():\n",
    "            print(f\"   > Measuring {entry.name}...\")\n",
    "            s = get_dir_size(entry.path)\n",
    "            subdirs.append((entry.name, s))\n",
    "    \n",
    "    subdirs.sort(key=lambda x: x[1], reverse=True)\n",
    "    print(\"\\nðŸš¨ BIGGEST FOLDERS IN PARENT:\")\n",
    "    for name, size in subdirs[:10]:\n",
    "        print(f\"   {fmt(size):<10} {name}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# 3. Check Trash specifically (Common culprit)\n",
    "trash = os.path.expanduser(\"~/.local/share/Trash\")\n",
    "if os.path.exists(trash):\n",
    "    print(f\"\\nðŸ—‘ï¸ Trash Size: {fmt(get_dir_size(trash))}\")\n",
    "    print(f\"   (Run 'import shutil; shutil.rmtree(\\\"{trash}\\\")' to empty it)\")\n",
    "else:\n",
    "    print(\"\\nâœ… No Trash folder found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ—‘ï¸ Emptying Trash at: /home/laughing_gates/.local/share/Trash ...\n",
      "âœ… Trash emptied! Disk space reclaimed.\n",
      "ðŸ’¾ New Free Space: 32 GB\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "# The path found by your scan\n",
    "trash_path = \"/home/laughing_gates/.local/share/Trash\"\n",
    "\n",
    "if os.path.exists(trash_path):\n",
    "    print(f\"ðŸ—‘ï¸ Emptying Trash at: {trash_path} ...\")\n",
    "    try:\n",
    "        shutil.rmtree(trash_path)\n",
    "        print(\"âœ… Trash emptied! Disk space reclaimed.\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error emptying trash: {e}\")\n",
    "else:\n",
    "    print(\"Trash is already empty.\")\n",
    "\n",
    "# Check space again\n",
    "total, used, free = shutil.disk_usage(\".\")\n",
    "print(f\"ðŸ’¾ New Free Space: {free // (2**30)} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Wh2-k5pPdIi_",
    "Qf0k-C1ofyEu",
    "elPV__umgg4O",
    "XKpXoe2WGOad",
    "vteisd-H5SeX"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
